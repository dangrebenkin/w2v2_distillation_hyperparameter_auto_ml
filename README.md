# w2v2_distillation_hyperparameter_auto_ml
The code for the knowledge distillation hyperparameter tuning task for AINL AutoML Workshop 2024 paper "Size Matters: About 
Optimal Amount of Speech Data for Student Hyperparameter Tuning in ASR Knowledge Distillation".
