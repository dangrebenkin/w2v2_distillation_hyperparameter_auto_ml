# w2v2_distillation_hyperparameter_auto_ml
The code for the knowledge distillation hyperparameter tuning task for AINL AutoML Workshop 2024 paper "Size Matters: About 
Optimal Amount of Speech Data for Student Hyperparameter Tuning in ASR Knowledge Distillation".

Conference: https://ainlconf.ru/

Workshop: https://ainlconf.ru/2024/automl